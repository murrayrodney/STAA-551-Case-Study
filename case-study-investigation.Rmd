---
title: "Case Study"
author: "Rodney Murray"
date: "2/25/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports, include=FALSE}
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
library(reshape)
library(car)
library(gridExtra)
library(formula.tools)
library(stringr)
library(broom)
```


# Summary statistics
First we will load a data and show the first few rows.
```{r data-load}
data <- read.csv('Prevend_Sample.csv')
names(data) <- tolower(names(data)) # Convert column names to lower case
head(data)
```
## Missing Values
First I will look for missing values.
```{r find-missing-values}
data <- select(data, -casenr) # we don't need the case number
colSums(is.na(data))
summary(data)

sum(data$hdl < 0)

sum(data$frs < 0)
```

It appears that we have no explicity missing values. 
We do have two values for `hdl` < 0, I will remove those an expect a minimal impact on the conclusions drawn later. We can always add those points back in if we are interested in a model that does not include `hdl`.
There appear to be some invalid values for `smoking` (< 0)
I'm also suspicious of `vat` < 0
I am suspicious of the values of `frs` < 0. I may remove those for now.
The rest of the values appear to be within their exp
```{r drop-nas}
data <- data %>% 
  replace(data < 0, NA) %>% # Replace all of the invalid values with NA
  drop_na() # Get rid of all of the rows with NA's
nrow(data)
```

It looks like if we drop all of the invalid values we will loose 42 observations. I will move forward with this since it may be unlikely to materially effect our conclusions. After we choose our model, it would be good to revisit and only drop na's for the columns that we are using in our model. We may also want to think about how the invalid values could have been generated and if there is a potential for that process to have effected the outcomes that we observe.

Now I will make all of the categorical variables in the data a factor type so that we can use them in our models without issues

```{r make-factors}
data <- mutate(data, 
       gender = factor(gender),
       ethnicity = factor(ethnicity),
       education = factor(education),
       cvd = factor(cvd),
       dm = factor(dm),
       smoking = factor(smoking),
       hypertension = factor(hypertension),
       albuminuria = factor(albuminuria),
       statin = factor(statin)
       )
```


## Distribution of prediction value and key values
We are interested in how different variables (particularly `statin`) effect cognitive decline `rfft`. We also have 19 other variables that we will decide what we will have to do with. First lets take a look at the distributions and potential relationship between `rfft` and `statin`.
* Because of our interested between these two variables we can say that our most basic model will be $rfft = \beta_0 + \beta_1 statin$.
* Because statin is a categorical variable with two levels, I imagine that we will likely find more variables that help describe variance in `rfft`
```{r plot-summaries}
fig <- ggplot(data, aes(x=rfft)) + geom_density()
fig

summary(data$statin)

fig <- ggplot(data, aes(x=statin, y=rfft)) + 
  geom_boxplot(fill='dodgerblue', alpha=0.4) +
  geom_jitter(height=0, width=0.25, alpha=0.5) +
  geom_blank()
fig
```

It does appear that there may be higher coginitive function with lower statin use. Before we build a model with this variable, lets take a look at how the numerical variables in our data correlate with `rfft`. 
Because there are too many variables to generate pair plots that we can read, I will calculate the correlation between all numerical variables in the data and make a heatmap that we can analyze.

```{r plot-correlations, warning=FALSE, message=FALSE}
data_num <- select_if(data, is.numeric)
corrs <- cor(data_num) %>%
  data.frame()
corrs <- corrs %>%  
  mutate(var1=rownames(corrs)) %>% 
  melt(id='var1')

corrs

ggplot(corrs, aes(var1, variable, fill=value)) + 
  geom_tile() +
  scale_fill_continuous(type='viridis')
  geom_blank()
```

It appears that our highest correlations with RFFT are with 
  * `chol` 
  * `egfr`
  * `hld`
  * `vat`
  
We will now look at some pairs plots to understand the potential correlations between these values.
```{r numerical-pair-plot}
cols <- c('chol', 'egfr', 'hdl', 'vat', 'rfft')
sub_data <- select(data, cols)
ggpairs(sub_data, aes(alpha=0.5))
```

It looks like `vat` and `rfft` have the most correlation, but none of the variables have a very high correlation.

Lets also look at some of the categorical variables 
```{r categorical-box-plots}
factor_data <- select_if(data, is.factor)
factor_cols <- names(factor_data)
plots <- 1:length(factor_cols)
count = 0
for (col in factor_cols) {
  count <-  count +1
  fig <- ggplot() + 
    geom_boxplot(aes(x=data[[col]], y=data[['rfft']])) +
    labs(x=col, y='RFFT')

  show(fig)
  plots[count] <- fig
}
```

It appears that some variables such as ethnicity and education could have significant impacts on the model.

# Modeling

```{r model-tracking}
track_model_perf <- function(model, new_model_name, prev_model_perf=NULL) {
  sum_obj <- summary(model)
  new_formula <- toString(sum_obj$terms)

  model_perf <- glance(model)
  model_perf$formula = new_formula
  model_perf$model_name = new_model_name
  
  if (!is.null(prev_model_perf)) {
    prev_model_perf <- filter(prev_model_perf, model_name != new_model_name)
    model_perf <-  bind_rows(prev_model_perf, model_perf)
    
  }
  
  return(model_perf)
}
model_perf <- data.frame()
```

## No Extra Categoricals
I will try a model without any extra categoricals, but we will include `statin` because it is a variable of interest in our study.
```{r model-no-extra-cats}
numerical_data <- select_if(data, is.numeric)
starting_data <- bind_cols(numerical_data, select(data, statin))

starting_model <- lm(rfft ~ ., starting_data)
summary(starting_model)
plot(starting_model)
model_perf <- track_model_perf(starting_model, 'Starting Model')
```
```{r model-no-extra-cat-interactions}
starting_interaction_model <- lm(rfft ~ .^2, starting_data)
summary(starting_interaction_model)
```


## Full model
Lets start with the full model and examine some of our assumptions
```{r full-model}
# Fit the full model, get a summary, and make interesting plots
full_model <- lm(rfft ~ ., data=data)

summary(full_model)

ggplot() + geom_point(aes(x=data$rfft, y=full_model$fitted.values))
plot(full_model) # Typical diagnostic plots
plot(full_model, 4) # Just cooks distances as bar
acf(full_model$residuals) # Looking for autocorrelation

model_perf <- track_model_perf(full_model, 'Full Model')
```

It appears that our F statistic says the model as a whole is describing a significant portion of data, but the adjusted (and multiple) R squared value is less than 0.5, so I suspect we have a ways to go. There are some variables that appear to be significant with the leave-one-out approach for the t-tests, there are a few with high p-values that we may choose to leave out of the model later on.

I don't see any clear trends in the mean of the residuals which is a good sign. I am worried about the constant variance assumption, so we may look at some transformations or WLS. The variance seems to increase as the fitted values increase. The QQ plot shows that there is no reason to believe that the residuals are not normally distributed. The cooks distances for our data do not indicate any points that we should likely be concerned about.

Let's take a quick look at the absolute values of the variance
```{r more-resid-plots}
fit_val <- full_model$fitted.values
resid <- full_model$residuals
abs_resid <- abs(resid)
resid_lm <- lm(abs_resid ~ fit_val)
summary(resid_lm)

fig <- ggplot() + 
  geom_point(aes(full_model$fitted.values, abs(full_model$residuals)), alpha=0.5) +
  geom_abline(
    intercept=resid_lm$coefficients['(Intercept)'], 
    slope=resid_lm$coefficients['fit_val'], 
    color='red') +
  labs(x='Fitted Values', y='Residuals')
fig
plot(resid_lm)
```
I went ahead and fit a linear model to the absolute value of the residuals to see what kind if trends it might reveal. Interestingly enough the p-values from the linear model seem to indicate that there could be a linear relationship in the residuals, looking at the $R^2$ value though shows that the model does not capture a large amount of variance (0.03) even though it is deemed significant by the F-test for the model!

## Transformations

### Box Cox
Lets try transforming the response with a Box Cox transformation
```{r box-cox-transformation}
boxCox(full_model)
```
From the above it might make sense to try a square root transformation


```{r plot-transformation}
trans_data <- mutate(data, rfft_sqrt = sqrt(rfft))
cols <- c('chol', 'egfr', 'hdl', 'vat', 'rfft_sqrt')
sub_data <- select(trans_data, cols)
ggpairs(sub_data, aes(alpha=0.5))
```
Hard to tell from this plot that it made any difference. We can quickly try the model

```{r model-box-cox}
trans_data <- select(trans_data, -rfft)
trans_full_model <- lm(rfft_sqrt ~ ., data=trans_data)
summary(trans_full_model)
plot(trans_full_model)

model_perf <- track_model_perf(trans_full_model, 'Full Model Box Cox', model_perf)
```

```{r look-at-resids}
fit_val <- trans_full_model$fitted.values
resid <- trans_full_model$residuals
abs_resid <- abs(resid)
trans_resid_lm <- lm(abs_resid ~ fit_val)
summary(trans_resid_lm)

fig <- ggplot() + 
  geom_point(aes(trans_full_model$fitted.values, abs(trans_full_model$residuals)), alpha=0.5) +
  geom_abline(
    intercept=trans_resid_lm$coefficients['(Intercept)'], 
    slope=trans_resid_lm$coefficients['fit_val'], 
    color='red') +
  labs(x='Fitted Values', y='Residuals')
fig
```
To be honest when I compare the plots side-by-side I feel like I have a hard time seeing any obvious differences in the plots after applying the square root transformation to the response variable. With that said the linear models appear to suggest that there is a low probability that we would see the trend in absolute values of residuals if there were no relationship, but this may be better addres with a WLS model.

Alternatively...after looking at the observed values vs. the fitted values, there may be some non-linear relationships that we should see if we can investigate.

### Interactions
```{r model-interactions}
inter_model <- lm(rfft ~ .^2, data=data)
summary(inter_model)
length(inter_model$coefficients)
plot(inter_model)
model_perf <- track_model_perf(inter_model, 'Full Model Interactions', model_perf)
```
Wow, that is a big model with > 200 coefficients! Certainly not something that we would want to keep, the R^2 is better but our adjusted R^2 is only marginally better and the AIC/BIC are worse since we have so many parameters. Can we get something that captures more variance, but with fewer parameters?
```{r interactions-metrics}
AIC(full_model)
AIC(inter_model)

BIC(full_model)
BIC(inter_model)
```

### Polynomial
```{r get-polynomial-formula}
numeric_data <- select_if(data, is.numeric)
numeric_data <- select(numeric_data, -rfft)
cols <- paste('poly(', names(numeric_data), ',2)', collapse = ' + ')

factor_cols <- names(select_if(data, is.factor))
factor_cols <- paste(factor_cols, collapse = ' + ')

cols <- paste(c(cols, factor_cols), collapse = ' + ')
formula <- paste('rfft ~ .^2 +', cols, collapse=' ')
formula <- paste('rfft ~ ', cols, collapse=' ')
# formula
formula <- as.formula(formula)
formula
```


```{r model-polynomial}
poly_model <- lm(formula, data=data)
print(length(poly_model$coefficients))
summary(poly_model)
length(poly_model$coefficients)
plot(poly_model)

model_perf <- track_model_perf(poly_model, 'Full Model Polynomials', model_perf)
```

## Feature Selection
### Full model
#### Forward AIC
```{r full-model-forward-AIC}
# Define the base model, scope, and execute the stepwise addition of variables
base_model <- lm(rfft ~ statin, data=data)
scope <- list(lower=base_model, upper=full_model)
forward_aic <- step(base_model, scope=scope, direction='forward', data=data, trace = 0)

# Analyze model
summary(forward_aic)
plot(forward_aic)
model_perf <- track_model_perf(forward_aic, 'Full Model Forward AIC', model_perf)
```


#### Backward AIC
```{r full-model-backward-AIC}
# Define base model, scoope and execute the stepwise removal of variables
base_model <- lm(rfft ~ statin, data=data)
scope <- list(lower=base_model, upper=full_model)
backward_aic <- step(full_model, scope=scope, direction='backward', data=data, trace=0)

# Analyze model
summary(backward_aic)
plot(backward_aic)
model_perf <- track_model_perf(backward_aic, 'Full Model Backward AIC', model_perf)
```

### Interactions
#### Forward AIC
```{r interactions-forward-AIC}
# Define base model, scope and execute stepwise addition of variables
base_model <- lm(rfft ~ statin, data=data)
scope <- list(lower=base_model, upper=inter_model)
forward_aic_inter <- step(base_model, scope=scope, direction='forward', data=data, trace=0)

# Analyze model
summary(forward_aic_inter)
plot(forward_aic_inter)
model_perf <- track_model_perf(forward_aic_inter, 'Interaction Model Forward AIC', model_perf)
```

```{r model-metrics}
AIC(starting_model)
AIC(full_model)
AIC(inter_model)
AIC(forward_aic_inter)

summary(starting_model)$adj.r.squared
summary(full_model)$adj.r.squared
summary(inter_model)$adj.r.squared
summary(forward_aic_inter)$adj.r.squared
```


### Polynomial
#### Forward AIC
We will take the polynomial model that we fit above, and see what features are really needed. Notice that for our base model we will at a minimum include the statin use since that is a variable of influence that we are particularly interested in.
```{r poly-forward-aic}
# Define base model, scope, and execute forward addition of variables
base_model <- lm(rfft ~ statin, data=data)
scope <- list(lower=base_model, upper=poly_model)
forward_aic_poly <- step(base_model, scope=scope, direction='forward', data=data, trace=0)

# Analyze model
summary(forward_aic_poly)
plot(forward_aic_poly)
model_perf <- track_model_perf(forward_aic_poly, 'Polynomial Model Forward AIC', model_perf)
```


#### Backward AIC
```{r poly-backward-AIC}
base_model <- lm(rfft ~ statin, data=data)
scope <- list(lower=base_model, upper=poly_model)
backward_aic_poly <- step(poly_model, scope=scope, direction='backward', data=data, trace=0)
summary(backward_aic_poly)
model_perf <- track_model_perf(backward_aic_poly, 'Polynomial Model Backward AIC', model_perf)
```

### Analyze model performance
We made some observations above, but it may be easier to compare everything here

```{r model-performance, fig.width=5, fig.height=3}
model_perf <- arrange(model_perf, AIC)
plot_model_perf <- filter(model_perf, !model_name %in% c('Full Model Box Cox', 'Full Model Interactions'))
select(plot_model_perf, model_name, adj.r.squared, AIC)



fig <- ggplot(plot_model_perf, aes(y=model_name, x=AIC)) + 
  geom_bar(stat='identity') +
  coord_cartesian(xlim=c(4000, 4200)) +
  geom_blank()
fig

fig <- ggplot(plot_model_perf, aes(x=adj.r.squared, y=AIC, label=model_name)) +
  geom_point(size=5, alpha=0.6, color='cornflowerblue') +
  geom_text(nudge_y = 1, check_overlap=TRUE) +
  xlim(0.445, 0.51) +
  labs(x=expression(Radj^2), y='AIC')
fig
```


